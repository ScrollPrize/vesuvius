{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cxSXq81lXO8n"
      },
      "source": [
        "In this tutorial, we will explore the basic concepts of accessing scroll data, processing them in a numpy-fashion, and also how to extract a small portion of the surface of the scroll. We call this last step \"segmentation\".\n",
        "\n",
        "### Steps Overview:\n",
        "1. **Access the Scroll**:\n",
        "   - Start by downloading the necessary scroll data.\n",
        "\n",
        "2. **Focus on a Smaller Region of the Volume**:\n",
        "   - Zoom in on a specific section of the data.\n",
        "\n",
        "3. **Plot a Histogram of Intensity Values**:\n",
        "   - Perform simple numpy operations on a small scroll chunk to create a histogram of intensity values.\n",
        "\n",
        "4. **Segmentation Fast Tutorial**:\n",
        "   - Demonstrate a simple proof-of-concept for segmenting a small portion of the scroll's surface. Note that segmenting a full scroll is much more complicated.\n",
        "\n",
        "   a. **Denoise**\n",
        "   \n",
        "   b. **Surface Detection**\n",
        "   \n",
        "   c. **Layer Extraction**\n",
        "   \n",
        "   d. **Flattening**\n",
        "   \n",
        "   e. **Meshing**\n",
        "\n",
        "### Getting Started:\n",
        "#### 1. Access the scroll\n",
        "First, we need to download the Vesuvius package, which will help us quickly fetch the scroll data from the repository.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A0Y1hHiJXikm",
        "outputId": "36d55d74-6526-41de-eb19-9ba4c920d98e"
      },
      "outputs": [],
      "source": [
        "#!pip install vesuvius\n",
        "#!vesuvius.accept_terms --yes;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnmqbkxQgylt"
      },
      "outputs": [],
      "source": [
        "import vesuvius\n",
        "from vesuvius import Volume\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dgI0rrD6lbxd"
      },
      "source": [
        "Great! Here's the next step for initializing a `Volume` object using Scroll 1. The canonical volume was scanned at 54keV and 7.91um resolution.\n",
        "\n",
        "This code snippet demonstrates how to install the Vesuvius package, import the `Volume` class. We can both load the canonical volume by just prompting \"scroll1\" or by specifying the scan metadata."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G4NnKHUelX2P",
        "outputId": "cb8ff5ae-a2d0-4221-bc97-4bf2fb0a9dc4"
      },
      "outputs": [],
      "source": [
        "scroll = Volume(\"Scroll1\", verbose=True)\n",
        "#scroll = Volume(\"scroll\", 1, 54, 7.91) this would also work"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTMCAqUxlQh3"
      },
      "source": [
        "scroll is a `Volume` object that points to the Scroll 1 volume scanned at 54keV and 7.91um on our online repository. It contains the volume scanned at the original resolution and subsampled versions of it. We can access to the data exactly as a numpy array. When we provide just 3 indices we will access automatically to the data in the original volume. If we provide 4 indices we are going to access to the subsampled volumes. The subsampled volume is specified by the fourth index. The first three indices will point to a smaller region of the volume. The reference frame will be indexed with the following convention: z, y, x."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DKrgXM4nDzQ"
      },
      "source": [
        "#### 2. Focus on a smaller region\n",
        "Let's focus on a smaller region, for instance let's focus on a single slice (z = 1000)[link text](https://)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "WjrJqsO4lMs8",
        "outputId": "25bd1aba-0a15-4e50-bc78-e1ea19e99395"
      },
      "outputs": [],
      "source": [
        "# visualizing a full slice of the volume downsampled at 63.28 um\n",
        "plt.imshow(scroll[1000,:,:,3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqmeOqfNlJq5"
      },
      "source": [
        "We can also check which files are available with the following command"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAjqjpxPk8lC"
      },
      "outputs": [],
      "source": [
        "file_dict = vesuvius.list_files()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TRoJYjuk60t",
        "outputId": "ee12f55f-de54-4d7c-bb13-0ba6f5132c0c"
      },
      "outputs": [],
      "source": [
        "print(file_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnJaP-ylnbv7"
      },
      "source": [
        "#### 3. Plotting a histogram of intensity values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eu5LWjU4k46-"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLtT2LWxk1SK",
        "outputId": "4b1ec885-8137-4bf1-9258-df9a266138a7"
      },
      "outputs": [],
      "source": [
        "scroll= Volume(\"Scroll1\", normalize=True) # normalize True activates normalization, values in {0, ..., 255} are mapped to [0,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TYHyqqs5RLvL"
      },
      "outputs": [],
      "source": [
        "scroll.meta() # print the available subvolumes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeguUslolsu6"
      },
      "outputs": [],
      "source": [
        "hist = np.histogram(scroll[1800:2000,1000:1200,1000:1200,2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594
        },
        "id": "Ue-4_OdVkt_1",
        "outputId": "09ade560-dd56-467f-f819-96327dc0754c"
      },
      "outputs": [],
      "source": [
        "# Calculate the bin centers\n",
        "bin_centers = (hist[1][1:] + hist[1][:-1]) / 2\n",
        "\n",
        "# Create the bar plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(bin_centers, hist[0], width=(hist[1][1] - hist[1][0]), color='skyblue', edgecolor='black')\n",
        "\n",
        "# Add labels and title\n",
        "plt.xlabel('Bin Centers')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Data')\n",
        "\n",
        "# Add grid lines\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "# Customize tick marks\n",
        "plt.xticks(bin_centers, rotation=45)\n",
        "plt.yticks(range(0, max(hist[0]) + 1, max(hist[0]) // 10))\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RtWebVlmc7n"
      },
      "source": [
        "#### 4. Segmentation Fast Tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfIbHhOg0ox6"
      },
      "source": [
        "Let us just plot a smaller portion of the previous slice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "ArwTt52YG-XN",
        "outputId": "0cd66270-8f62-4237-e1a8-0d89d439be0a"
      },
      "outputs": [],
      "source": [
        "plt.imshow(scroll[7000,4600:4800,4000:4200])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKnjPTCvuO8O"
      },
      "source": [
        "We are going to get our hands dirty and extract a little piece of surface from this data. We will apply the following steps:\n",
        "\n",
        "a. **Denoise**\n",
        "b. **Surface Detection**\n",
        "c. **Layer Extraction**\n",
        "d. **Flattening**\n",
        "e. **Meshing**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKzu0nWpuUKy"
      },
      "source": [
        "**a. Denoise**\n",
        "We are going to denoise the data to make it more easily manipulable by the surface detection in the next step. We have to do it because the surface detection leverages approximations of the gradient (local difference in voxel intensity) that can be disturbed by noise.\n",
        ":\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y72jNw76vJTq",
        "outputId": "76047000-c1df-4ea1-b16b-09b7854a5e2c"
      },
      "outputs": [],
      "source": [
        "!pip install scikit-image PyWavelets\n",
        "from skimage.restoration import estimate_sigma, denoise_nl_means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PTAkNirv2Uh"
      },
      "outputs": [],
      "source": [
        "# Download data chunk into numpy array\n",
        "chunk = scroll[7000:7100,4600:4800,4000:4200]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omFd-kJUvb_w"
      },
      "outputs": [],
      "source": [
        "# Estimate variance in the chunk\n",
        "sigma = estimate_sigma(chunk)\n",
        "# Denoise with non-local means using the extracted sigma\n",
        "chunk = denoise_nl_means(chunk, patch_size=7, patch_distance=3, sigma=sigma, h=0.03)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "BIhKUHXXwLMc",
        "outputId": "c2d33d8c-0699-4b02-f2ed-65db8fb888b0"
      },
      "outputs": [],
      "source": [
        "plt.imshow(chunk[20,:,:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRHoKAo0xKqg"
      },
      "source": [
        "**b. Surface detection**\n",
        "Let's define an algorithm to detect the surface. What we are going to use will evaluate the gradient and the hessian at every voxel in the denoised chunk and select only those voxels that have a gradient magnitude higher than a threshold AND the determinant of the Hessian lower than another threshold. This helps focusing on the surface and neglecting blobs. Later, we perform Non-Maximum Suppression to make the extracted surface thin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tg1tZ1wWxdNG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.ndimage import convolve, map_coordinates\n",
        "\n",
        "def divide_nonzero(array1, array2):\n",
        "    precision = array1.dtype\n",
        "    denominator = np.copy(array2)\n",
        "    denominator[denominator == 0] = np.finfo(precision).tiny\n",
        "    return np.divide(array1, denominator)\n",
        "\n",
        "def calculate_det(a,b,c,d,e,f):\n",
        "    det = np.abs(a*(b*c-e**2)-d*(d*c-e*f)+f*(d*e-b*f))\n",
        "    return det\n",
        "\n",
        "def normalize_gradient(a,b):\n",
        "    return a/b\n",
        "\n",
        "def grad_and_det(volume, precision):\n",
        "    a = np.zeros((volume.shape[0], volume.shape[1], volume.shape[2]), dtype=precision)\n",
        "    b = np.zeros((volume.shape[0], volume.shape[1], volume.shape[2]), dtype=precision)\n",
        "    c = np.zeros((volume.shape[0], volume.shape[1], volume.shape[2]), dtype=precision)\n",
        "    d = np.zeros((volume.shape[0], volume.shape[1], volume.shape[2]), dtype=precision)\n",
        "    e = np.zeros((volume.shape[0], volume.shape[1], volume.shape[2]), dtype=precision)\n",
        "    f = np.zeros((volume.shape[0], volume.shape[1], volume.shape[2]), dtype=precision)\n",
        "\n",
        "    # Using Pavel Holoborodko's derivative\n",
        "    pavel_1d = np.array([2,1,-16,-27,0,27,16,-1,-2], dtype=precision)  # Derivative approximation\n",
        "    pavel_1d_smooth = np.array([1, 4, 6, 4, 1], dtype=precision)  # Smoothing\n",
        "    pavel_1d_2nd = np.array([-7,12,52,-12,-90,-12,52,12,-7], dtype=precision)\n",
        "\n",
        "    # Create 3D kernels by outer products and normalization\n",
        "    kz = np.outer(np.outer(pavel_1d, pavel_1d_smooth), pavel_1d_smooth).reshape(9, 5, 5)/ (96*16*16)\n",
        "    ky = np.outer(np.outer(pavel_1d_smooth, pavel_1d), pavel_1d_smooth).reshape(5, 9, 5)/ (96*16*16)\n",
        "    kx = np.outer(pavel_1d_smooth, np.outer(pavel_1d_smooth, pavel_1d)).reshape(5, 5, 9)/ (96*16*16)\n",
        "    kzz = np.outer(np.outer(pavel_1d_2nd, pavel_1d_smooth), pavel_1d_smooth).reshape(9, 5, 5)/ (192*16*16)\n",
        "    kyy = np.outer(np.outer(pavel_1d_smooth, pavel_1d_2nd), pavel_1d_smooth).reshape(5, 9, 5)/ (192*16*16)\n",
        "    kxx = np.outer(pavel_1d_smooth, np.outer(pavel_1d_smooth, pavel_1d_2nd)).reshape(5, 5, 9)/ (192*16*16)\n",
        "\n",
        "    gradient = np.zeros((3, volume.shape[0], volume.shape[1], volume.shape[2]), dtype=np.float32)\n",
        "\n",
        "    a = convolve(volume, kzz)\n",
        "    b = convolve(volume, kyy)\n",
        "    c = convolve(volume, kxx)\n",
        "\n",
        "    gradient[0] = convolve(volume, kz)\n",
        "    d = convolve(gradient[0], ky)\n",
        "    f = convolve(gradient[0], kx)\n",
        "\n",
        "    gradient[1] = convolve(volume, kx)\n",
        "    e = convolve(gradient[1], kx)\n",
        "\n",
        "    gradient[2] = convolve(volume, kx)\n",
        "\n",
        "    det = calculate_det(a,b,c,d,e,f)\n",
        "\n",
        "    del a, b, c, d, e, f\n",
        "\n",
        "    magnitude = np.sqrt(gradient[0]**2+gradient[1]**2+gradient[2]**2)\n",
        "\n",
        "    gradient = normalize_gradient(gradient, magnitude)\n",
        "\n",
        "    return det, gradient, magnitude\n",
        "\n",
        "def nms_3d(magnitude, grad):\n",
        "    \"\"\"\n",
        "    Applies Non-Maximum Suppression on a 3D volume using interpolation along gradient directions.\n",
        "\n",
        "    Parameters:\n",
        "    - magnitude: 3D cupy array representing the magnitude of gradients.\n",
        "    - grad: 3D cupy array of shape (3, *magnitude.shape) representing gradient vectors.\n",
        "\n",
        "    Returns:\n",
        "    - nms_volume: 3D numpy array after applying NMS.\n",
        "    \"\"\"\n",
        "\n",
        "    # Get the shape of the volume\n",
        "    z_dim, y_dim, x_dim = magnitude.shape\n",
        "\n",
        "    # Create meshgrid of indices\n",
        "    Z, Y, X = np.meshgrid(np.arange(z_dim), np.arange(y_dim), np.arange(x_dim), indexing='ij')\n",
        "\n",
        "    # Calculate continuous indices for forward and backward positions based on gradients\n",
        "    forward_indices = np.array([Z, Y, X]) + grad\n",
        "    backward_indices = np.array([Z, Y, X]) - grad\n",
        "\n",
        "    # Interpolate the magnitude values at these continuous indices\n",
        "    forward_values = map_coordinates(magnitude, forward_indices, order=1, mode='nearest')\n",
        "    backward_values = map_coordinates(magnitude, backward_indices, order=1, mode='nearest')\n",
        "\n",
        "    # Apply conditions for NMS using logical functions\n",
        "    condition1 = np.logical_and(magnitude >= forward_values, magnitude > backward_values)\n",
        "    condition2 = np.logical_and(magnitude > forward_values, magnitude >= backward_values)\n",
        "    mask = np.logical_or(condition1, condition2)\n",
        "\n",
        "    # Apply mask to set NMS volume\n",
        "    magnitude[~mask] = 0\n",
        "\n",
        "    return magnitude\n",
        "\n",
        "def surface_detection(volume, precision, threshold_grad=0.2, threshold_det=0.001):\n",
        "    det, gradient, magnitude = grad_and_det(volume, precision)\n",
        "    magnitude = nms_3d(magnitude, gradient)\n",
        "    det /= det.max()\n",
        "    magnitude /= magnitude.max()\n",
        "    mask = (det < threshold_det) & (magnitude > threshold_grad)\n",
        "    del det, gradient, magnitude\n",
        "    edges = np.zeros((volume.shape[0], volume.shape[1], volume.shape[2]), dtype=np.uint8)\n",
        "    edges[mask] = 1\n",
        "    return edges"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvSL5z3sygxu"
      },
      "outputs": [],
      "source": [
        "surface = surface_detection(chunk, np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "A50_AXuRynYC",
        "outputId": "5411e5e6-d630-4c98-a7c6-f71517fe44d6"
      },
      "outputs": [],
      "source": [
        "plt.imshow(surface[20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X3hUTu5wy1Yr"
      },
      "source": [
        "The previous algorithm flagged some voxels as on-surface, but we actually want only the recto surface of every sheet -- the one on which text is written. To do so, we can just use the value of the gradient computed on each voxel flagged as on-surface and check that the dot product with a vector coming from the main axis of the scroll is positive. In this tutorial let's assume that this vector is just (0,-1,0)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbAHFrraytmP"
      },
      "outputs": [],
      "source": [
        "vector = np.array([0,-1,0], dtype=np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYHu2w11zxIO"
      },
      "outputs": [],
      "source": [
        "_, gradient, _ = grad_and_det(chunk, np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3nfDol6S0GiH"
      },
      "outputs": [],
      "source": [
        "dot_product = np.einsum('xdhw,x->dhw', gradient, vector)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLGvDy_n0Ova"
      },
      "outputs": [],
      "source": [
        "recto_chunk = surface & (dot_product > 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "ss0TvpZt1BUL",
        "outputId": "27c17ccd-f783-4de3-a486-56c8ba848205"
      },
      "outputs": [],
      "source": [
        "plt.imshow(recto_chunk[50])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltvmf0rs1js0"
      },
      "source": [
        "**c. Layer extraction**\n",
        "Let us extract a single layer / segment.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6P7BoYuC5hp"
      },
      "source": [
        "We install the library connected-components-3d that can help us cluster connected components of nearby flagged voxels in a 3D array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19dsuwyH1h8D",
        "outputId": "98ef39bf-3b1d-488c-a0c9-154fd0bff4b4"
      },
      "outputs": [],
      "source": [
        "!pip install connected-components-3d\n",
        "# or run\n",
        "#!pip uninstall connected-components-3d -y\n",
        "#!pip install connected-components-3d --no-binary :all:\n",
        "import cc3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKDlWmnx1vrd"
      },
      "outputs": [],
      "source": [
        "labels_out, N = cc3d.connected_components(recto_chunk, return_N=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6x2p_8Y82OfY",
        "outputId": "4045b6e3-ad37-434c-da26-46f9a4b28e76"
      },
      "outputs": [],
      "source": [
        "N"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-jjoCFc2gna"
      },
      "source": [
        "We extracted N different connected components 😞, let's focus on a big one!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vnrvz7_72gCg"
      },
      "outputs": [],
      "source": [
        "labels_out, N = cc3d.largest_k(\n",
        "  recto_chunk, k=1,\n",
        "  connectivity=26, delta=0,\n",
        "  return_N=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xXwHuVla5H99"
      },
      "outputs": [],
      "source": [
        "segment = labels_out == 1 # taking only the voxels corresponding to label (connected component) number 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "P7sHqn2S2JF0",
        "outputId": "cee1e7ca-eebe-42af-8a70-fd9f71a3a1ff"
      },
      "outputs": [],
      "source": [
        "plt.imshow(segment[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4FvuBKF3kbf"
      },
      "source": [
        "**d. Flattening**\n",
        "we obtained a chunk with only some voxel on the recto surface of a sheet flagged as 1.\n",
        "Now we are goint to convert it to a point cloud and flatten it. For simplicity we are going to do an orthographic projection since this is a small piece of surface with no much curvature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PqbqH-U3k27"
      },
      "outputs": [],
      "source": [
        "points = np.argwhere(segment == 1).astype(np.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5-b91Qp4BfR"
      },
      "outputs": [],
      "source": [
        "flat_points = points[:,:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "bYCMZC8Q48H7",
        "outputId": "e1d01c94-e8af-464c-e62a-21de8ec41ff8"
      },
      "outputs": [],
      "source": [
        "plt.scatter(flat_points[:,0],flat_points[:,1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmVRsZFv7CyF"
      },
      "source": [
        "As you may notice, the projection has several holes and missing parts. This is because the algorithm to extract point cloud did not map those voxels as on-surface due to the imposed thresholding."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg6dSMQL7yXE"
      },
      "source": [
        "**e. Meshing**\n",
        "In order to render this segment we need to build up the connectivity: we need to connect the dots. This means that we need to create a triangular mesh. We can do it on the flattened point cloud. Let us the class `Delaunay` to compute a Delaunay triangulation in 2D."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrdDJHsj7-GA"
      },
      "outputs": [],
      "source": [
        "from scipy.spatial import Delaunay\n",
        "tri = Delaunay(flat_points)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "bTyRZnYc8HWC",
        "outputId": "83a09012-e0da-406b-e9ad-471834dbd56f"
      },
      "outputs": [],
      "source": [
        "plt.triplot(flat_points[:,0], flat_points[:,1], tri.simplices)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j8oABwy-8ov6"
      },
      "source": [
        "Great! We have obtained an approximately decent triangular mesh! This mesh can translate the same connectivity to the 3D point cloud. This is possible because `tri.simplices` contains the indices of the points used as vertices of every triangle. But this is out of the scope of this tutorial!\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Scroll Data Access",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
